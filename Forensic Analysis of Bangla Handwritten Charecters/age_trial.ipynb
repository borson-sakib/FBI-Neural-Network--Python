{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "age_trial.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "SerCTTlPnyoU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import asarray\n",
        "import numpy as np\n",
        "import pickle\n",
        "import keras\n",
        "import warnings\n",
        "import sklearn.model_selection as sk\n",
        "from keras import backend as k\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation\n",
        "from keras.layers.core import Dense, Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras.metrics import categorical_crossentropy\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import *\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "%matplotlib  inline\n",
        "from os import listdir\n",
        "from matplotlib import image\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "from keras.layers import Reshape\n",
        "from keras.optimizers import SGD\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.optimizers import SGD\n",
        "from matplotlib import pyplot \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9b3Xr1WpPej",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzyLvQmVv4_t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd \"/content/drive/My Drive/BanglaLekha/images\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqO3L6kpxjii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path  = \"5/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1Wuf8rNpQA0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Adolescent = []\n",
        "Adult = []\n",
        "for r, d, file in os.walk(path):\n",
        "    for i in file:\n",
        "        print(i)\n",
        "        if(int(i[10:12]))<18:\n",
        "          Adolescent.append(cv2.imread(os.path.join(path,i),cv2.IMREAD_COLOR))\n",
        "        else:\n",
        "          Adult.append(cv2.imread(os.path.join(path,i),cv2.IMREAD_COLOR))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_265hGnC60N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Re_Adolescent = []\n",
        "Re_Adult = []\n",
        "IMG_SIZE = 128\n",
        "for i in range(len(Adolescent)):\n",
        "  resized = cv2.resize(Adolescent[i],(IMG_SIZE,IMG_SIZE))\n",
        "  Re_Adolescent.append(resized)\n",
        "  \n",
        "for i in range(len(Adult)):\n",
        "  resized1 = cv2.resize(Adult[i],(IMG_SIZE,IMG_SIZE))\n",
        "  Re_Adult.append(resized1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWQpGrw-EY24",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = []\n",
        "for i in Re_Adolescent:\n",
        "  train.append([i,0])\n",
        "  \n",
        "for i in Re_Adult:\n",
        "    train.append([i,1])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8fpfv3hEdq3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random.shuffle(train)\n",
        "for batch in train[0:50]:\n",
        "    print(batch[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYTdxjfiEdx7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train =[]\n",
        "Y_train =[]\n",
        "\n",
        "for f,l in train:\n",
        "    X_train.append(f)\n",
        "    Y_train.append(l)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exlvpLftU5RO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OphQ5NDJEd1p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "IMG_SIZE = 128\n",
        "\n",
        "X_train = np.array(X_train).reshape(-1,IMG_SIZE,IMG_SIZE,3)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcfHZeY7X9n7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kNu8x4kFbxw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp_test = Y_train.copy()\n",
        "temp_test  = np.array(temp_test)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxyookB_tdN9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp_test.shape\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSzBMdfOFftr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "def define_model():\n",
        "\t# load model\n",
        "\tmodel = VGG16(include_top=False, input_shape=(128,128,3))\n",
        "\t# mark loaded layers as not trainable\n",
        "\tfor layer in model.layers:\n",
        "\t\tlayer.trainable = False\n",
        "\t# add new classifier layers\n",
        "\tflat1 = Flatten()(model.layers[-1].output)\n",
        "\tclass1 = Dense(128, activation='relu', kernel_initializer='he_uniform')(flat1)\n",
        "\toutput = Dense(1, activation='sigmoid')(class1)\n",
        "\t# define new model\n",
        "\tmodel = Model(inputs=model.inputs, outputs=output)\n",
        "\t# compile model\n",
        "\topt = SGD(lr=0.001, momentum=0.9)\n",
        "\tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\treturn model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gh6EJjUNFfxW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def summarize_diagnostics(history):\n",
        "\t# plot loss\n",
        "\tpyplot.subplot(211)\n",
        "\tpyplot.title('Cross Entropy Loss')\n",
        "\tpyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
        "\t# plot accuracy\n",
        "\tpyplot.subplot(212)\n",
        "\tpyplot.title('Classification Accuracy')\n",
        "\tpyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "\tpyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "\t# save plot to file\n",
        "\tfilename = sys.argv[0].split('/')[-1]\n",
        "\tpyplot.savefig(filename + '_plot.png') \n",
        "\tpyplot.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7osoUEXFf0b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1017BBlwFf4D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train1, X_test1, y_train, y_test =  sk.train_test_split(X_train,temp_test,test_size=0.3, random_state = 42)\n",
        "\n",
        "y_test.shape\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxnE7B8xLCYW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def run_test_harness():\n",
        "\t# define model\n",
        "\tmodel = define_model()\n",
        "\thistory = model.fit(X_train1, y_train, batch_size=200, epochs=35,verbose = 1)\n",
        "\tfilename = 'finalized_model.sav'\n",
        "\tpickle.dump(model, open(filename, 'wb'))\t\n",
        "\t# evaluate model\n",
        "\t_, acc = model.evaluate(X_test1, y_test, verbose=1)\n",
        "\tprint('> %.3f' % (acc * 100.0))\n",
        "\t# learning curves\n",
        "\tsummarize_diagnostics(history)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4HD88awIVFu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "run_test_harness()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eu3keerCIVXI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loaded_model = pickle.load(open('finalized_model.sav', 'rb'))\n",
        "result = loaded_model.evaluate(X_test1, y_test)\n",
        "print(result)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}